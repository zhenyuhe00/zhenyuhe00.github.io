---
permalink: /
title: ""
# excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
# About me

I am a second-year PhD student at Peking University advised by incredible Prof.[Di He](https://dihe-pku.github.io/). I'm interested in deep learning and its application to NLP and AI4science. Currently, I'm a research intern at ByteDance Doubao (Seed) with [Jingjing Xu](https://scholar.google.com/citations?user=8HZzDSwAAAAJ&hl=zh-CN). I've also interned at MSRA with [Lijun Wu](https://apeterswu.github.io/) and DP Technology with [Guolin Ke](https://guolinke.github.io/).


## Publication
Let the Code LLM Edit Itself When You Edit the Code, **ICLR 2025** [[paper](https://arxiv.org/abs/2407.03157)] [[code](https://github.com/zhenyuhe00/PIE)]<br>
**Zhenyu He**, Jun Zhang, Shengjie Luo, Jingjing Xu, Zhi Zhang, Di He

Exploiting Pre-trained Models for Drug Target Affinity Prediction with Nearest Neighbors, **CIKM 2024** [[paper](https://arxiv.org/abs/2407.15202)] <br>
Qizhi Pei, Lijun Wu, **Zhenyu He**, Jinhua Zhu, Yingce Xia, Shufang Xie, Rui Yan

Two Stones Hit One Bird: Bilevel Positional Encoding for Better Length Extrapolation, **ICML 2024** [[paper](https://arxiv.org/abs/2401.16421)] [[code](https://github.com/zhenyuhe00/BiPE)] [[paperweekly](https://mp.weixin.qq.com/s/9Ibi4CNcvEcjRRJwyIAmwg)] <br>
**Zhenyu He**\*, Guhao Feng\*, Shengjie Luo\*, Kai Yang, Liwei Wang, Jingjing Xu, Zhi Zhang, Hongxia Yang, Di He

Do Efficient Transformers Really Save Computation?, **ICML 2024** [[paper](https://arxiv.org/abs/2402.13934)] <br>
Kai Yang, Jan Ackermann, **Zhenyu He**, Guhao Feng, Bohang Zhang, Yunzhen Feng, Qiwei Ye, Di He, Liwei Wang

REST: Retrieval-Based Speculative Decoding, **NAACL 2024** [[paper](https://arxiv.org/abs/2311.08252)] [[code](https://github.com/FasterDecoding/REST)] [[blog](https://sites.google.com/view/rest-llm/)] [[paperweekly](https://mp.weixin.qq.com/s/6Zt_tg4N_uNFEtrLdzEOVw)] <br>
**Zhenyu He**\*, Zexuan Zhong\*, Tianle Cai\*, Jason D. Lee, Di He

Uni-Fold MuSSe: De Novo Protein Complex Prediction with Protein Language Models, **ICLR 2023 MLDD workshop**, [[paper](https://www.biorxiv.org/content/10.1101/2023.02.14.528571v1)] [[code](https://github.com/dptech-corp/Uni-Fold/tree/MuSSe)] <br>
Jinhua Zhu\*, **Zhenyu He**\*, Ziyao Li, Guolin Ke, Linfeng Zhang

Rumor Detection on Social Media with Event Augmentations, **SIGIR 2021**(short) [[paper](https://dl.acm.org/doi/pdf/10.1145/3404835.3463001)]  [[code](https://github.com/hzy-hzy/RDEA)] <br>
**Zhenyu He**\*, Ce Li\*, Fan Zhou, Yi Yang
## Preprint

Examining User-Friendly and Open-Sourced Large GPT Models: A Survey on Language, Multimodal, and Scientific GPT Models, arXiv 2023 [[paper](https://arxiv.org/abs/2308.14149)] <br>
Kaiyuan Gao\*, Sunan He\*, **Zhenyu He**\*, Jiacheng Lin\*, Qizhi Pei\*, Jie Shao\*, Wei Zhang\*

Two-Stage Neural Contextual Bandits for Personalised News Recommendation, arXiv 2022 [[paper](https://arxiv.org/abs/2206.14648)] <br>
Mengyan Zhang, Thanh Nguyen-Tang, Fangzhao Wu, **Zhenyu He**, Xing Xie, Cheng Soon Ong

## Education Experience

<dl><dt><img align="left" width="80" height="80" hspace="10" src="images/pku.png" /></dt><dt> Peking University</dt>
<dd>Sep. 2023 - Now</dd>
<dd>PhD student, School of Artificial Intelligence</dd></dl>

<dl><dt><img align="left" width="80" height="80" hspace="10" src="images/uestc.jpeg" /></dt><dt> University of Electronic Science and Technology of China</dt>
<dd>Sep. 2019 - Jun. 2023</dd>
<dd>B.E. in Software Engineering</dd>
<dd>GPA: 91+/100 </dd></dl>

## Awards

Peking University Presidential Scholarship (the highest doctoral research honor at Peking University)

## Professional Services
Reviewer for ICML 2024, COLM 2024, NeurIPS 2024, ICLR 2025.

