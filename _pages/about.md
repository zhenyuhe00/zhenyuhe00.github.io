---
permalink: /
title: ""
# excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
# About me

I am a third-year PhD student at Peking University advised by the incredible Prof.[Di He](https://dihe-pku.github.io/). Currently, I am an intern at ByteDance Seed. I have also previously interned at Microsoft Research Asia and DP Technology.

## Recent Focus
I recently focused on enhancing the coding agent capabilities of LLMs. Selected work:
1. Led the development of SWE-Swiss, a 32B open-weight model that achieves top-tier performance on SWE-bench Verified. [[Notion](https://www.notion.so/SWE-Swiss-A-Multi-Task-Fine-Tuning-and-RL-Recipe-for-High-Performance-Issue-Resolution-21e174dedd4880ea829ed4c861c44f88#245174dedd488067a9e7eea04315dad5)] [[code](https://github.com/zhenyuhe00/SWE-Swiss)]
2. Contribute to Doubao Seed Code and Seed 1.8.


## Publication
Let the Code LLM Edit Itself When You Edit the Code, **ICLR 2025** [[paper](https://arxiv.org/abs/2407.03157)] [[code](https://github.com/zhenyuhe00/PIE)]<br>
**Zhenyu He**, Jun Zhang, Shengjie Luo, Jingjing Xu, Zhi Zhang, Di He

Exploiting Pre-trained Models for Drug Target Affinity Prediction with Nearest Neighbors, **CIKM 2024** [[paper](https://arxiv.org/abs/2407.15202)] <br>
Qizhi Pei, Lijun Wu, **Zhenyu He**, Jinhua Zhu, Yingce Xia, Shufang Xie, Rui Yan

Two Stones Hit One Bird: Bilevel Positional Encoding for Better Length Extrapolation, **ICML 2024** [[paper](https://arxiv.org/abs/2401.16421)] [[code](https://github.com/zhenyuhe00/BiPE)] [[paperweekly](https://mp.weixin.qq.com/s/9Ibi4CNcvEcjRRJwyIAmwg)] <br>
**Zhenyu He**\*, Guhao Feng\*, Shengjie Luo\*, Kai Yang, Liwei Wang, Jingjing Xu, Zhi Zhang, Hongxia Yang, Di He

Do Efficient Transformers Really Save Computation?, **ICML 2024** [[paper](https://arxiv.org/abs/2402.13934)] <br>
Kai Yang, Jan Ackermann, **Zhenyu He**, Guhao Feng, Bohang Zhang, Yunzhen Feng, Qiwei Ye, Di He, Liwei Wang

REST: Retrieval-Based Speculative Decoding, **NAACL 2024** [[paper](https://arxiv.org/abs/2311.08252)] [[code](https://github.com/FasterDecoding/REST)] [[blog](https://sites.google.com/view/rest-llm/)] [[paperweekly](https://mp.weixin.qq.com/s/6Zt_tg4N_uNFEtrLdzEOVw)] <br>
**Zhenyu He**\*, Zexuan Zhong\*, Tianle Cai\*, Jason D. Lee, Di He

Uni-Fold MuSSe: De Novo Protein Complex Prediction with Protein Language Models, **ICLR 2023 MLDD workshop**, [[paper](https://www.biorxiv.org/content/10.1101/2023.02.14.528571v1)] [[code](https://github.com/dptech-corp/Uni-Fold/tree/MuSSe)] <br>
Jinhua Zhu\*, **Zhenyu He**\*, Ziyao Li, Guolin Ke, Linfeng Zhang

Rumor Detection on Social Media with Event Augmentations, **SIGIR 2021**(short) [[paper](https://dl.acm.org/doi/pdf/10.1145/3404835.3463001)]  [[code](https://github.com/hzy-hzy/RDEA)] <br>
**Zhenyu He**\*, Ce Li\*, Fan Zhou, Yi Yang

## Awards

2023-2024: Presidential Scholarship (the highest doctoral research honor at Peking University)

## Professional Services
Reviewer for  
ICML 2024, 2025, 2026   
NeurIPS 2024, 2025  
ICLR 2025, 2026  
COLM 2024

